{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px; width: 55px\">\n",
    "\n",
    "# Introduction to Web Scraping and Spiders with `scrapy`\n",
    "\n",
    "_Authors: Dave Yerrington (SF), Sam Stack(DC)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the structure and content of HTML\n",
    "- Learn about elements, attributes, and element hierarchy in HTML\n",
    "- Learn about XPath and using multiple and singular selections\n",
    "- Practice using Scrapy to get data from craigslist\n",
    "- Practice using Beautiful Soup to parse data from craigslist\n",
    "- Walkthrough the construction of a spider built using scrapy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Introduction](#introduction)\n",
    "- [HTML](#html)\n",
    "    - [Elements](#elements)\n",
    "    - [Attributes](#attributes)\n",
    "    - [Element hierarchy](#element-hierarchy)\n",
    "    - [More resources on HTML structure](#html-resources)\n",
    "- [What is XPath?](#xpath)\n",
    "    - [Multiple selections](#multiple-selections)\n",
    "    - [Singular selections](#singlular-selections)\n",
    "- [A simple `scrapy` example](#scrapy)\n",
    "- [A practical example with Requests and Beautiful Soup](#practical)\n",
    "    - [Step 1: fetch the content by URL](#step1)\n",
    "    - [Step 2: Parse HTML document with Beautiful Soup](#step2)\n",
    "    - [Practice: can you select the price of our junker?](#practice)\n",
    "- [Scrapy and spiders](#scrapy)\n",
    "    - [Create a Scrapy project](#scrapy-project)\n",
    "    - [Define an \"item\"](#define-item)\n",
    "    - [A spider that crawls](#spider-crawl)\n",
    "    - [XPath and parsing with our spider](#xpath-spider)\n",
    "    - [Save and examine our scraped data](#save-examine)\n",
    "- [Addendum: leveraging XPath to get more results](#addendum)\n",
    "    - [Following links](#follow-links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Introduction](#introduction)\n",
    "- [HTML](#html)\n",
    "    - [Elements](#elements)\n",
    "    - [Attributes](#attributes)\n",
    "- [What is XPath?](#xpath)\n",
    "    - [Absolute References](#xpath_absolute)\n",
    "    - [Relative References](#xpath_relative)\n",
    "    - [\"Wheres Waldo?\" Exercise](#waldo_exercise)\n",
    "- [1 vs N Selectors](#1_v_n)\n",
    "- [Demo Code](#demo)\n",
    "    - [Scrape Data Tau](#scrape_tau)\n",
    "- [Independent Practice](#ind_practice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "\n",
    "![What is Html](http://designshack.designshack.netdna-cdn.com/wp-content/uploads/htmlbasics-0.jpg)\n",
    "\n",
    "One of the largest sources of data in the world is all around us.  We consume the web in some form every day.  One of the most powerful python toolsets we will learn allows us to extract and normalize data from unstructured sources like webpages.  \n",
    "\n",
    "**If you can see it, it can be scraped, mined, and put into a dataframe.**\n",
    "\n",
    "Before we begin the actual process of webscraping with python, it is important to cover the basic constructs that describe HTML as unstructured data. \n",
    "\n",
    "Then we will cover a a powerful selection technique called XPath, and look at a basic workflow using a framework called [Scrapy](http://www.scrapy.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='html'></a>\n",
    "\n",
    "## Hypertext markup language (HTML)\n",
    "\n",
    "---\n",
    "\n",
    "In the HTML DOM (Document Object Model), everything is a node:\n",
    " * The document itself is a document node.\n",
    " * All HTML elements are element nodes.\n",
    " * All HTML attributes are attribute nodes.\n",
    " * Text inside HTML elements are text nodes.\n",
    " * Comments are comment nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='elements'></a>\n",
    "### Elements\n",
    "Elements begin and end with open and close \"tags\", which are defined by namespaced, encapsulated strings. These namespaces that begin and end the elements must be the same.\n",
    "\n",
    "```\n",
    "<title>I am a title.</title>\n",
    "<p>I am a paragraph.</p>\n",
    "<strong>I am bold.</strong>\n",
    "```\n",
    "\n",
    "As you may have several different titles or paragraphs on a single page, you can assign ID values to namespace to make more unique reference points.  IDs are also very useful for labelling nested elements.\n",
    "```\n",
    "<title id ='title_1'>I am a the first title.</title>\n",
    "<p id ='para_1'>I am the first paragraph.</p>\n",
    "<title id ='title_2'>I am a the second title.</title>\n",
    "<p id ='para_2'>I am the second paragraph.</p>\n",
    "```\n",
    "\n",
    "\n",
    "**Elements can have parents and children:**\n",
    "It is important to remember that an element can be both a parent and a child and whether to refer to the element as a parent or a child depends on the specific element you are referencing.\n",
    "\n",
    "\n",
    "```\n",
    "<body id = 'parent'>\n",
    "    <div id = 'child_1'>I am the child of 'parent'\n",
    "        <div id = 'child_2'>I am the child of 'child_1'\n",
    "            <div id = 'child_3'>I am the child of 'child_2'\n",
    "                <div id = 'child_4'>I am the child of 'child_4'</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "```\n",
    "**or**\n",
    "```\n",
    "<body id = 'parent'>\n",
    "    <div id = 'child_1'>I am the parent of 'child_2'\n",
    "        <div id = 'child_2'>I am the parent of 'child_3'\n",
    "            <div id = 'child_3'> I am the parent of 'child_4'\n",
    "                <div id = 'child_4'>I am not a parent </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='attributes'></a>\n",
    "### Attributes\n",
    "\n",
    "HTML elements can have attributes.  They describe properties, and characteristics of elements.  Some affect how the element behaves or looks in terms of the rendered output by the browser.\n",
    "\n",
    "The most common element is an \"anchor\" element.  Anchor elements often have an \"href\" element, which tells the browser where to go after it is clicked.  Anchor elements are typically are formatted in bold, and sometimes are underlined as a visual cue to differentiate itself.\n",
    "\n",
    "**Markup that describes nn element with attributes, litterally looks like this**\n",
    "\n",
    "```\n",
    "<a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">An Awesome Website</a>\n",
    "```\n",
    "\n",
    "**However, this element, once rendered, looks like this**\n",
    "\n",
    "[An Awesome Website](https://www.youtube.com/watch?v=dQw4w9WgXcQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='element-hierarchy'></a>\n",
    "### Element hierarchy\n",
    "\n",
    "![Nodes](http://www.computerhope.com/jargon/d/dom1.jpg)\n",
    "\n",
    "**Literally Represented:**\n",
    "\n",
    "```\n",
    "<html>\n",
    "    \n",
    "    <head>\n",
    "        <title>Example</title>\n",
    "    </head>\n",
    "    \n",
    "    <body>\n",
    "        <h1>Example Page</h1>\n",
    "        <p>This is an example page.</p>\n",
    "    </body>\n",
    "    \n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='html-resources'></a>\n",
    "### You are now qualified HTML experts\n",
    "\n",
    "![](assets/certified.jpg)\n",
    "\n",
    "Your HTML learning can continue...\n",
    "\n",
    "Read all about the different elements supported amongst modern browsers:\n",
    " * [HTML5 Cheatsheet](http://websitesetup.org/html5-cheat-sheet/)\n",
    " * [Mozilla HTML Element Reference](https://developer.mozilla.org/en-US/docs/Web/HTML/Element)\n",
    " * [HTML5 Visual Cheatsheet](http://www.unitedleather.biz/PDF/HTML5-Visual-Cheat-Sheet1.pdf)\n",
    " \n",
    "From here on out, we will talking mostly about how to select these different elments with XPath:\n",
    "\n",
    "- Single vs multiple elements\n",
    "- Elements, conditionally matching attributes\n",
    "- Element attributes\n",
    "- Element text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='xpath'></a>\n",
    "\n",
    "## What is XPath?\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"assets/obama_wiki.png\" width=\"700\">\n",
    "\n",
    "Understanding how to identify elements and attributes within HTML documents gives us the capability to write simple expressions that create structured data.  We can think os XPath like a query language for querying HTML.\n",
    "\n",
    "To make this process easier to deal with, we will be using XPath helper, which is a Chrome addon.  It's not necessary, but highly recommended to help build XPath expressions.\n",
    "\n",
    "[XPath Helper](https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en)\n",
    "\n",
    "XPath expressions can select elements, element attributes, and element text.  These selections can be either to a single item, or multiple items.  Generally, if you're not specific enough, you will end up selecting multiple elements.\n",
    "\n",
    "\n",
    "<a id='multiple-selections'></a>\n",
    "### Multiple selections\n",
    "\n",
    "***Multiple selections*** are useful for capturing search results, or any repeating element.  For instance, the _titles_ of an apartment listing search results from Craigslist:\n",
    "\n",
    "\n",
    "**URL**\n",
    "\n",
    "[http://sfbay.craigslist.org/search/sfc/apa](http://sfbay.craigslist.org/search/sfc/apa)\n",
    "\n",
    "\n",
    "**Example HTML Markup**\n",
    "```\n",
    "...\n",
    "<span class=\"pl\"> \n",
    "    <time datetime=\"2016-01-12 23:27\" title=\"Tue 12 Jan 11:27:35 PM\">Jan 12</time> \n",
    "    <a href=\"/sfc/apa/5400584579.html\" data-id=\"5400584579\" class=\"hdrlnk\">Welcome home to a sweetly renovated four bedroom one and a half bath</a> \n",
    "</span>\n",
    "...\n",
    "```\n",
    "\n",
    "**XPath - Multiple Titles** _copy this into the XPath Helper Query box_\n",
    "```\n",
    "//a[@class='result-title hdrlnk']\n",
    "```\n",
    "\n",
    "**Returns (Ad Titles)**\n",
    "```\n",
    "***New Remodeled two bedroom Apartment***\n",
    "WONDERFUL ONE BR APARTMENT HOME\n",
    "Beautiful 1bed/1bath Apartment in Russian Hill NO SECURITY DEPOSIT\n",
    "Knockout SF View|Green Oasis|Private Driveway|Furnished\n",
    "3BR/3BA Spacious, Beautiful SOMA Loft: 5 month lease\n",
    "Nob Hill Large Studio - Light, Quiet, Lovely Building\n",
    "etc...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='singlular-selections'></a>\n",
    "\n",
    "### Singular selections\n",
    "\n",
    "***Singular selections*** are necessary when you want to grab specific, unique text within elements.  Here's an example of a details page on Craigslist:\n",
    "\n",
    "> *Note: this example may be expired if you view it sometime after Jan 12th, 2016. Please replace this with a current craigslist listing!\n",
    "\n",
    "**URL**\n",
    "\n",
    "[https://sfbay.craigslist.org/sfc/apa/6161864063.html](https://sfbay.craigslist.org/sfc/apa/6161864063.html)\n",
    "\n",
    "**HTML Markup**\n",
    "\n",
    "```\n",
    "<div class=\"postinginfos\">\n",
    "    <p class=\"postinginfo\">post id: 5400585892</p>\n",
    "    <p class=\"postinginfo\">posted: <time datetime=\"2016-01-12T23:23:19-0800\" class=\"xh-highlight\">2016-01-12 11:23pm</time></p>\n",
    "    <p class=\"postinginfo\"><a href=\"https://accounts.craigslist.org/eaf?postingID=5400585892\" class=\"tsb\">email to friend</a></p>\n",
    "    <p class=\"postinginfo\"><a class=\"bestof-link\" data-flag=\"9\" href=\"https://post.craigslist.org/flag?flagCode=9&amp;postingID=5400585892\" title=\"nominate for best-of-CL\"><span class=\"bestof-icon\">♥ </span><span class=\"bestof-text\">best of</span></a> <sup>[<a href=\"http://www.craigslist.org/about/best-of-craigslist\">?</a>]</sup>    </p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "**XPath - Single Item**\n",
    "\n",
    "```\n",
    "//p[@class='postinginfo'][2]/time\n",
    "```\n",
    "**Returns (Time of posting or age of Post)**\n",
    "```\n",
    "2016-01-12 11:23pm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scrapy'></a>\n",
    "\n",
    "## A simple  example using `scrapy` and `XPath`.\n",
    "\n",
    "---\n",
    "\n",
    "Below is an example of how to get information out of some fake HTML using the XPath capabilities of the `scrapy` package. You will likely need to install the scrapy package using `conda install scrapy`.   \n",
    "**Note:** `Conda install` will install the necessary dependent packages needed for Scrapy, `pip install` will **not**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `Selector` class from the `Scrapy` library to help us construct our query.\n",
    "\n",
    "`Selector` classes take the HTML target as an argument and can then utilize several flavors of query types to extract information.  In our situation we will specify `XPath` as our query will utilize XPath flavoured language. \n",
    "\n",
    "Just like with writing python scripts, there are several was you can access the exact same information in HTML.  Lets try a few out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img src=\"https://secure.gravatar.com/avatar/26da7b36ff8bb5db4211400358dc7c4e.jpg?s=512&r=g&d=mm\" style=\"float: left; width: 90px; padding: -15px 25px 25px 0\">If you're on Docker with the `scipy-notebook` version of Jupyter, you will need to temporarily install the Scrapy library for this lesson today.  If not, no need to run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata ...........\n",
      "Solving package specifications: .\n",
      "\n",
      "# All requested packages already installed.\n",
      "# packages in environment at /opt/conda:\n",
      "#\n",
      "scrapy                    1.4.0                    py36_0    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda install scrapy --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best of']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "# HTML structure string\n",
    "HTML = \"\"\"\n",
    "<div class=\"postinginfos\">\n",
    "    <p class=\"postinginfo\">post id: 5400585892</p>\n",
    "    <p class=\"postinginfo\">posted: <time datetime=\"2016-01-12T23:23:19-0800\" class=\"xh-highlight\">2016-01-12 11:23pm</time></p>\n",
    "    <p class=\"postinginfo\"><a href=\"https://accounts.craigslist.org/eaf?postingID=5400585892\" class=\"tsb\">email to friend</a></p>\n",
    "    <p class=\"postinginfo\"><a class=\"bestof-link\" data-flag=\"9\" href=\"https://post.craigslist.org/flag?flagCode=9&amp;postingID=5400585892\" title=\"nominate for best-of-CL\"><span class=\"bestof-icon\">♥ </span><span class=\"bestof-text\">best of</span></a> <sup>[<a href=\"http://www.craigslist.org/about/best-of-craigslist\">?</a>]</sup>    </p>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Option 1: use the exact class name to get its associated text\n",
    "best = Selector(text=HTML).xpath(\"//span[@class='bestof-text']/text()\").extract()\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best of']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2: use the 'contains()' function extract any text that includes the text 'best of'\n",
    "best = Selector(text=HTML).xpath(\"//span[contains(text(), 'best of')]/text()\").extract()\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best of']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 3: First grabs the entire html post where 'class='bestof-link'\n",
    "best =  Selector(text=HTML).xpath(\"/html/body/div/p/a[@class='bestof-link']\")\n",
    "        # parse the first grabbed chunk for the the text of the specific element with class='bestof-text'\n",
    "nested_best =  best.xpath(\"./span[@class='bestof-text']/text()\").extract()\n",
    "nested_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Option 3 will probably be the most common for you because there is a good chance that you will want to grab information from several children elements that exist within one parent element._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where's Waldo - \"XPath Edition\"\n",
    "\n",
    "In this example, we will find Waldo together.  Find Waldo as:\n",
    "\n",
    "- Element\n",
    "- Attribute\n",
    "- Text element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        \n",
    "        <ul id=\"waldo\">\n",
    "            <li class=\"waldo\">\n",
    "                <span> yo Im not here</span>\n",
    "            </li>\n",
    "            <li class=\"waldo\">Height:  ???</li>\n",
    "            <li class=\"waldo\">Weight:  ???</li>\n",
    "            <li class=\"waldo\">Last Location:  ???</li>\n",
    "            <li class=\"nerds\">\n",
    "                <div class=\"alpha\">Bill gates</div>\n",
    "                <div class=\"alpha\">Zuckerberg</div>\n",
    "                <div class=\"beta\">Theil</div>\n",
    "                <div class=\"animal\">parker</div>\n",
    "            </li>\n",
    "        </ul>\n",
    "        \n",
    "        <ul id=\"tim\">\n",
    "            <li class=\"tdawg\">\n",
    "                <span>yo im here</span>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <li>stuff</li>\n",
    "        <li>stuff2</li>\n",
    "        \n",
    "        <div id=\"cooldiv\">\n",
    "            <span class=\"dsi-rocks\">\n",
    "               YO!\n",
    "            </span>\n",
    "        </div>\n",
    "        \n",
    "        \n",
    "        <waldo>Waldo</waldo>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** We can use the asterisk special character '*' as an place holder for 'all possible'.\n",
    "\n",
    "```python\n",
    "# all elements where class='alpha'\n",
    "Selector(text=HTML).xpath('//*[@class=\"alpha\"]').extract()\n",
    "\n",
    "#returns\n",
    "\n",
    "[u'<div class=\"alpha\">Bill gates</div>',\n",
    " u'<div class=\"alpha\">Zuckerberg</div>']\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find element 'waldo'\n",
    "\n",
    "Notice this is an absolute reference like a file directory.  The \"//\" slash refers to \"all elements that end with `[element name]`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Waldo']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text contents of the element waldo\n",
    "Selector(text=HTML).xpath('/html/body/waldo/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find attribute(s) 'waldo'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<ul id=\"waldo\">\\n            <li class=\"waldo\">\\n                <span> yo Im not here</span>\\n            </li>\\n            <li class=\"waldo\">Height:  ???</li>\\n            <li class=\"waldo\">Weight:  ???</li>\\n            <li class=\"waldo\">Last Location:  ???</li>\\n            <li class=\"nerds\">\\n                <div class=\"alpha\">Bill gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">parker</div>\\n            </li>\\n        </ul>',\n",
       " '<li class=\"waldo\">\\n                <span> yo Im not here</span>\\n            </li>',\n",
       " '<li class=\"waldo\">Height:  ???</li>',\n",
       " '<li class=\"waldo\">Weight:  ???</li>',\n",
       " '<li class=\"waldo\">Last Location:  ???</li>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contents of all elements with all attributes with value waldo\n",
    "Selector(text=HTML).xpath('//*[@*=\"waldo\"]').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<li class=\"waldo\">\\n                <span> yo Im not here</span>\\n            </li>',\n",
       " '<li class=\"waldo\">Height:  ???</li>',\n",
       " '<li class=\"waldo\">Weight:  ???</li>',\n",
       " '<li class=\"waldo\">Last Location:  ???</li>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contents of all elements (*) with class attributes set to waldo\n",
    "Selector(text=HTML).xpath('//*[@class=\"waldo\"]').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find text element Waldo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<waldo>Waldo</waldo>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gets everything around the text element waldo\n",
    "Selector(text=HTML).xpath(\"//*[text()='Waldo']\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's practice with the class a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Select only \"beta\" nerds, text element\n",
    "There's a list item that has a class \"nerds\".  First try to select that list item, conditionally with the class \"nerds\".  Then, extend your query to also select the child elements with the \"beta\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Select only \"alpha\" nerds, text element\n",
    "There's a list item that has a class \"nerds\".  First try to select that list item, conditionally with the class \"nerds\".  Then, extend your query to also select the child elements with the \"alpha\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) _Absolutely_ select only the span text when ANY element has the class \"tdawg\"\n",
    "Remember, absolute references start from the beginning of your DOM reference.  What is the first element in your document?  This will be the first element that you select beginning with a single slash \"/\".\n",
    "\n",
    "_Bonus points, which popular series (without googling) is the charcter \"T-Dawg\" from?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Select all the child elements of nerd, but then only their \"class\" attributes\n",
    "\n",
    "Relative or absolute reference.  The XPath query should return: alpha, alpha, beta, animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Any text element that _contains_ the text \"yo\"\n",
    "We haven't talked about this much but you can also do substring matches using the `contains(source, match)` within `[]` brackets.  It can match elements, attributes, or text elements as the source.  The match paramter is a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Here's an example that shows \"li\" tags that match the @class \"waldo\"._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<li class=\"waldo\">\\n                <span> yo Im not here</span>\\n            </li>',\n",
       " '<li class=\"waldo\">Height:  ???</li>',\n",
       " '<li class=\"waldo\">Weight:  ???</li>',\n",
       " '<li class=\"waldo\">Last Location:  ???</li>']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath(\"//li[contains(@class, 'waldo')]\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Try this same query with all (*), instead of \"li\", and the selector for text elements instead of @class_. \n",
    "\n",
    ">This one conditional selection method is very flexible and you will find it handy in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Nested Content Problem\n",
    "(Double click this tab to see the source example if you're in Jupyter lab.)\n",
    "\n",
    "Imagine if you will, you have a piece of content like this:\n",
    "\n",
    "```html\n",
    "<div id=\"item_12345\">\n",
    "    Here is a great new website I found called <strong>thistothat.com</strong> which has practically been around forever.  Back in <em>1997</em>, I told all my friends about this and because of this knowledge transfer, I became <strong>the most popular man in <em>Alaska</em></strong>\n",
    "<div>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<div id=\"item_12345\">\n",
    "    Here is a great new website I found called <strong>thistothat.com</strong> which has practically been around forever.  Back in <em>1997</em>, I told all my friends about this and because of this knowledge transfer, I became <strong>the most popular man in <em>Alaska</em></strong>\n",
    "<div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Here is a great new website I found called ',\n",
       " ' which has practically been around forever.  Back in ',\n",
       " ', I told all my friends about this and because of this knowledge transfer, I became ',\n",
       " '\\n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=html).xpath(\"//div[@id='item_12345']/text()\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's returned relative to what we expected?\n",
    "\n",
    "Seems like we have a structure that kind of looks like this:\n",
    "\n",
    "```\n",
    "<div> \n",
    "    [1. a text element] \n",
    "    <strong> [2. a text element] </strong> \n",
    "    [3. another text element] \n",
    "    <em> [4. text element] </em>\n",
    "    [5. another text element -- starts with \"I told all my friends...\"]\n",
    "    <strong> \n",
    "        [6. text element - \"the most popular man in\"]\n",
    "        <em> [7. text element - \"Alaska\"] </em>\n",
    "    </strong>\n",
    "</div>\n",
    "```\n",
    "\n",
    "If we ask **XPath** to give us the **text()** elements of within the _1st_ level of our **//div** object(s), it's going to do _exactly_ that.  The first level of text elements are items _1, 3, and 5_.  Now, this is where XPath can be a little bit obtuse so in these cases we might be able to use **BeautifulSoup** in order to collapse these nested elements to produce a text element that looks like what you see.  \n",
    "\n",
    "**BeautifulSoup** has much more functionality for selecting HTML by CSS selector, generalized filtering methods, and even cleaning bad HTML to be formatted correctly.  We are simply going to use it to capture these nested text elements in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's see how to get this nested collection of text elements with XPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    Here is a great new website I found called ',\n",
       " 'thistothat.com',\n",
       " ' which has practically been around forever.  Back in ',\n",
       " '1997',\n",
       " ', I told all my friends about this and because of this knowledge transfer, I became ',\n",
       " 'the most popular man in ',\n",
       " 'Alaska']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "div_text        =  Selector(text=html).xpath(\"//div[@id='item_12345']/text()\").extract()\n",
    "em_text         =  Selector(text=html).xpath(\"//div[@id='item_12345']/em/text()\").extract() \n",
    "strong_text     =  Selector(text=html).xpath(\"//div[@id='item_12345']/strong/text()\").extract()\n",
    "strong_em_text  =  Selector(text=html).xpath(\"//div[@id='item_12345']/strong/em/text()\").extract()\n",
    "\n",
    "extracted_text = [div_text[0], strong_text[0], div_text[1], em_text[0], div_text[2], strong_text[1], strong_em_text[0]]\n",
    "extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've captured the text in the right format in the right order, in a list, we can `join` all elements as a single text string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Here is a great new website I found called  thistothat.com  which has practically been around forever.  Back in  1997 , I told all my friends about this and because of this knowledge transfer, I became  the most popular man in  Alaska'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(extracted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's a lot of work so let's try this with BeautifulSoup\n",
    "\n",
    "To use BeautifulSoup, we just import it, initialize a `soup` object with `BeautifulSoup` class, passing the HTML content as a string, to the first parameter.  The 2nd parameter is the parser you wish to use with BeautifulSoup.  Mainly the parser is an underlying library that scans the HTML document providing the low level hooks **BeautifulSoup** uses, enabling all of it's features to read the lower level document elements.  Some parsers perform differently and other provide more parsing features of HTML.  \"lxml\" is based on LibXML and works great for pasing HTML documents.\n",
    "\n",
    "Here's how we collapse nested text elements in 1 line of BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Here is a great new website I found called thistothat.com which has practically been around forever.  Back in 1997, I told all my friends about this and because of this knowledge transfer, I became the most popular man in Alaska\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "soup.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are a few handy operations with BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference elements by class variable / object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div id=\"item_12345\">\n",
       "    Here is a great new website I found called <strong>thistothat.com</strong> which has practically been around forever.  Back in <em>1997</em>, I told all my friends about this and because of this knowledge transfer, I became <strong>the most popular man in <em>Alaska</em></strong>\n",
       "<div>\n",
       "</div></div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference element attributes by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'item_12345'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.div['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference nested elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<strong>thistothat.com</strong>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.div.strong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference items with powerful selectors**\n",
    "\n",
    "Like **.next\\_element** and **.previous\\_element**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' which has practically been around forever.  Back in '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This selects the 2nd strong element\n",
    "soup.div.strong.next_element.next_element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select relative parents (which element owns the own in question?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Here is a great new website I found called \n",
      "<strong>thistothat.com</strong>\n",
      " which has practically been around forever.  Back in \n",
      "<em>1997</em>\n",
      ", I told all my friends about this and because of this knowledge transfer, I became \n",
      "<strong>the most popular man in <em>Alaska</em></strong>\n",
      "\n",
      "\n",
      "<div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "for element in soup.div.strong.find_parent():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for elements by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<strong>thistothat.com</strong>,\n",
       " <strong>the most popular man in <em>Alaska</em></strong>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll(\"strong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read more about [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) in the [docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "BeautifulSoup is a wonderful complement to XPath because it's nice to collapse text and even strip HTML out of chunks of text that you've selected with XPath, eliminating a lot of work involved with iterating slicing through nested elements.  It's still, in a lot of ways not as powerful as XPath when it comes to query flexibility and performance.\n",
    "\n",
    "_XPath can sometimes be thought of a relic from the past but it's extremely well suited for any size job, providing enough basic features to be useful and learned within a day or two.  You can certainly learn all of it's features like date trasnformations and formatters, but it's not going to make you any less productive._\n",
    "<br><br>\n",
    "\n",
    "><img src=\"https://snag.gy/3FGbPo.jpg\" width=\"450\">\n",
    ">[Python HTML Parser Performance](http://blog.ianbicking.org/2008/03/30/python-html-parser-performance/)\n",
    ">This is an old article but BeautfulSoup does tend to be a bit slower if you have a larger job, you might consider measuring the resource utilization of your scrape / crawl methods before you decide to go fully BeautifulSoup.\n",
    "\n",
    "#### One last thought about alternative parsing methods\n",
    "One up and coming library in python is [pyquery](https://pypi.python.org/pypi/pyquery).  If you're an old salty Javascript developer, you might feel at home being able to use JQuery style selectors.  This is wildly powerful as it suports pseudo CSS class selectors and other nicities not found in either BeautifulSoup or XPath.\n",
    "\n",
    "## What to use and when\n",
    "$$Friends = 2*\\frac{XPath * BeautifulSoup}{XPath + BeautifulSoup}$$\n",
    "\n",
    "Generally, learn XPath well because we recommend using it as your default go-to since it's widely used in Scrapy which will help you scrape multiple pages and large scale jobs.  XPath offers the most flexibility overall, and is reasonable enough to learn.  Use BeautifulSoup for nested elements, smaller projects, and generally when it's easier to select items with objects and elements you extract with XPath to pull out the little items burried within.  Also use BeautifulSoup when your HTML is malformed and nothing seems to work with it.  Optionally learn the CSS selector queries because they can all work with scrapy's XPath implementation.\n",
    "\n",
    "> **Read more about CSS selectors**\n",
    "> * [W3Schools CSS Selectors](https://www.w3schools.com/cssref/css_selectors.asp)\n",
    "> * [Tuts Plus: 30 Selectors You Must Memorize](https://code.tutsplus.com/tutorials/the-30-css-selectors-you-must-memorize--net-16048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alaska']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Xpath with chained CSS selector\n",
    "Selector(text=html).xpath(\"//div\").css(\"strong em::text\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Repeating Elements\n",
    "\n",
    "The most common pattern you will likely encounter in your web scraping adventures, will be search results.  Search result type pages are best scraped by selecting the highest level repeating element, then iterating through them and extracting their child elements.\n",
    "\n",
    "Let's say we're talking about job postings on Indeed.com:\n",
    "\n",
    "<img src=\"https://snag.gy/aOV15P.jpg\" width=\"600\">\n",
    "\n",
    "Each item is a job posting.  Each job posting has a **Job Title** that links to a details page about the job, a **Company Name**, and a brief **Job Description**.  Sometimes, it doesn't have **reviews** but other times it does.\n",
    "\n",
    "There are two obvious strategies, but really only one is going to work in this case.\n",
    "\n",
    "1. **Selecting and extracting Title, Company, Ratings, and Job Description seperately**\n",
    "1. **Selecting the container element that contains each job posting and extracting the Title / Company / Ratings / Description within iteration.**\n",
    "\n",
    "### Look at the reviews for a minute.  Can you think of tradeoffs or problems with either approach?\n",
    "Think about how we might turn this into a DataFrame for a moment, given either case 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<div class=\"row  result\">\n",
    "    \n",
    "    <a class=\"jobtitle\">Data Scientist II</a>\n",
    "    <span class=\"company\">Big Fish Games</span>\n",
    "    <span class=\"ratings\">13 reviews</span>\n",
    "    <span class=\"location\">Oakland, CA 94612</span>\n",
    "    <span class=\"summary\">The Data Scientists are responsible for applying a wide... </span>\n",
    "    \n",
    "<div>\n",
    "\n",
    "<div class=\"row  result\">\n",
    "    \n",
    "    <a class=\"jobtitle\">Machine Learning (Comprehend) Engineer</a>\n",
    "    <span class=\"company\">ipvive</span>\n",
    "\n",
    "    <span class=\"location\">Berkeley, CA 94704</span>\n",
    "    <span class=\"summary\">The ei-OS Machine Learning (Comprehend) Engineer will lead </span>\n",
    "    \n",
    "<div>\n",
    "\n",
    "<div class=\"row  result\">\n",
    "\n",
    "    <a class=\"jobtitle\">Senior Data Scientist</a>\n",
    "    <span class=\"company\">Big Fish Games</span>\n",
    "    <span class=\"ratings\">13 reviews</span>\n",
    "    <span class=\"location\">Oakland, CA 94612</span>\n",
    "    <span class=\"summary\">The Data Scientists are responsible for applying a wide... </span>\n",
    "    \n",
    "<div>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: selecting each element individually\n",
    "\n",
    "Can you think of some ways to make this a dataframe?  Any problems?  Go head an inspect these items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles =  Selector(text=html).xpath(\"//a[@class='jobtitle']\").extract()\n",
    "companies  =  Selector(text=html).xpath(\"//span[@class='company']\").extract()\n",
    "ratings    =  Selector(text=html).xpath(\"//span[@class='ratings']\").extract()\n",
    "locations  =  Selector(text=html).xpath(\"//span[@class='location']\").extract()\n",
    "summary    =  Selector(text=html).xpath(\"//span[@class='summary']\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: Iterate through parent elements, extracting titles / ratings / etc.\n",
    "Check this code out and try to think through how and why it works.  Feel free to print out anything and think through how this is better or worse than the first case.  Is this this really better or more complicated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'company': 'Big Fish Games',\n",
       "  'location': 'Oakland, CA 94612',\n",
       "  'rating': '13 reviews',\n",
       "  'summary': 'The Data Scientists are responsible for applying a wide... ',\n",
       "  'title': 'Data Scientist II'},\n",
       " {'company': 'ipvive',\n",
       "  'location': 'Berkeley, CA 94704',\n",
       "  'rating': 'N/A',\n",
       "  'summary': 'The ei-OS Machine Learning (Comprehend) Engineer will lead ',\n",
       "  'title': 'Machine Learning (Comprehend) Engineer'},\n",
       " {'company': 'Big Fish Games',\n",
       "  'location': 'Oakland, CA 94612',\n",
       "  'rating': '13 reviews',\n",
       "  'summary': 'The Data Scientists are responsible for applying a wide... ',\n",
       "  'title': 'Senior Data Scientist'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postings = []\n",
    "\n",
    "# the contains() XPath function will substring match any item you put in it\n",
    "# we use this to find the class \"row\" within the class attribute that says \"row result\"\n",
    "for selector in Selector(text=html).xpath(\"//div[contains(@class, 'row')]\"):  # also notice we didn't extract()\n",
    "    \n",
    "    ## Each \"row\" ie: Job title, being extracted is referenced by selector\n",
    "    postings.append({\n",
    "        # the . in front of the XPath query makes the reference relative to the current row in iteration\n",
    "        \"title\":    selector.xpath(\"./a[@class='jobtitle']/text()\").extract_first(default=\"N/A\"),\n",
    "        \"company\":  selector.xpath(\"./span[@class='company']/text()\").extract_first(default=\"N/A\"),\n",
    "        \"rating\":   selector.xpath(\"./span[@class='ratings']/text()\").extract_first(default=\"N/A\"),\n",
    "        \"location\": selector.xpath(\"./span[@class='location']/text()\").extract_first(default=\"N/A\"),\n",
    "        \"summary\":  selector.xpath(\"./span[@class='summary']/text()\").extract_first(default=\"N/A\")\n",
    "    })\n",
    "    \n",
    "postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>rating</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Big Fish Games</td>\n",
       "      <td>Oakland, CA 94612</td>\n",
       "      <td>13 reviews</td>\n",
       "      <td>The Data Scientists are responsible for applyi...</td>\n",
       "      <td>Data Scientist II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ipvive</td>\n",
       "      <td>Berkeley, CA 94704</td>\n",
       "      <td>N/A</td>\n",
       "      <td>The ei-OS Machine Learning (Comprehend) Engine...</td>\n",
       "      <td>Machine Learning (Comprehend) Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Fish Games</td>\n",
       "      <td>Oakland, CA 94612</td>\n",
       "      <td>13 reviews</td>\n",
       "      <td>The Data Scientists are responsible for applyi...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          company            location      rating  \\\n",
       "0  Big Fish Games   Oakland, CA 94612  13 reviews   \n",
       "1          ipvive  Berkeley, CA 94704         N/A   \n",
       "2  Big Fish Games   Oakland, CA 94612  13 reviews   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The Data Scientists are responsible for applyi...   \n",
       "1  The ei-OS Machine Learning (Comprehend) Engine...   \n",
       "2  The Data Scientists are responsible for applyi...   \n",
       "\n",
       "                                    title  \n",
       "0                       Data Scientist II  \n",
       "1  Machine Learning (Comprehend) Engineer  \n",
       "2                   Senior Data Scientist  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(postings)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If need be, demonstrate parent / child elements of selectors here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Requests - Practice\n",
    "The requests library is very powerful.  While it's not practical for large scale sites, you can do a lot in a pinch.  Let's try to scrape a basic site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "response = requests.get(\"http://econpy.pythonanywhere.com/ex/001.html\")\n",
    "html = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you extract the buyer-info elements into a DataFrame?  Try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you develop a function or class that takes a url, parses the page elements, finds the next page, then parses the next page?  \n",
    "\n",
    "Try to finish this code.  You can do it!  The only thing left to do is to update the code staring on line 29 which if you followed the same pattern as we did in the 2nd case previously, you should be able to extract the name and the amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing next page:  http://econpy.pythonanywhere.com/ex/002.html\n",
      "Parsing next page:  http://econpy.pythonanywhere.com/ex/003.html\n",
      "Parsing next page:  http://econpy.pythonanywhere.com/ex/004.html\n",
      "Parsing next page:  http://econpy.pythonanywhere.com/ex/005.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>,\n",
       " <Selector xpath=\"//div[@title='buyer-info']\" data='<div title=\"buyer-info\">\\n  <div title=\"b'>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
